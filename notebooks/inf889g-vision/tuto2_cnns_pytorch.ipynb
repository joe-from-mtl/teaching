{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGC2D_19Re73"
   },
   "source": [
    "# Tutoriel 2 : Réseau de neurones à convolution\n",
    "***INF889G - Vision par ordinateur (UQÀM)***\n",
    "\n",
    "Adapté du [tutoriel 2](https://github.com/pjreddie/uwimg/blob/main/tutorial2_cnns_in_pytorch.ipynb) du cours CSE455 à l'Université de Washington (J. Redmon).\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joe-from-mtl/teaching/blob/main/notebooks/inf889g-vision/tuto2_cnns_pytorch.ipynb)\n",
    "\n",
    "Ce tutoriel explore les convets avec l'ensemble de données [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html). Commençons par importer les modules python utilisés par ce tutoriel et par vérifier si un GPU est accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOVeMnEcLrt4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eYxX893R_4P"
   },
   "source": [
    "## Obtenir les données du Cifar\n",
    "C'est assez simple, on peut tout simplement utiliser les fonctionnalités intégrée de PyTorch pour construire un ensemble de données. Pour ce tutoriel, nous utiliserons également de l'augmentation de données (*data augmentation*).\n",
    "\n",
    "**`RandomCrop(32, padding=4)`** : Cela signifie que nous allons rogner des régions 32x32 aléatoires de l'image ayant dabord été augmentée par un remplissage de zéros de taille 4 pixels (*zero padding*). Étant donné que l'image est de taille 32x32, cela signifie que nous devons d'abord faire un remplissage de zéro pour en faire une image de taille 40x40 (en ajoutant 4 pixels par côté), puis choisir aléatoirement et rogner une région 32x32. Cela signifie que le réseau voit une version de l'image légèrement décalée à chaque fois, il est donc plus difficile de surajuster des pixels spécifiques à des endroits spécifiques. Cela oblige le réseau à apprendre des filtres plus robustes et réduit le surajustement.\n",
    "\n",
    "**`RandomHorizontalFlip()`** : Ceci signifie que la moitié du temps l'image sera retournée horizontalement. La raison est la même que plus huat, le réseau voit des versions différentes des données, ce qui rend plus difficile le surajustement.\n",
    "\n",
    "**Note:** l'augmentation des données est déasctivé par défaut. On essaiera d'entraîner le réseau normalement, puis nous évaluerons l'effet de l'augmentation des données sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4zbAcWsL-JM"
   },
   "outputs": [],
   "source": [
    "def get_cifar10_data(augmentation: bool=False) -> dict:\n",
    "    # Transformations de type \"augmentation des données\"\n",
    "    # Ce n'est pas pour les tests !\n",
    "    if augmentation:\n",
    "        transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode='edge'), # Rogner une région 32x32 depuis une image rembourrée (padded) 40x40\n",
    "        transforms.RandomHorizontalFlip(),    # 50% du temps faire une réflection horizontale selon l'axe y\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "    else: \n",
    "        transform_train = transforms.ToTensor()\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
    "                                        transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True,\n",
    "                                            num_workers=20)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
    "                                      transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False,\n",
    "                                          num_workers=20)\n",
    "    classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    return {'train': trainloader, 'test': testloader, 'classes': classes}\n",
    "\n",
    "data = get_cifar10_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqLGlQPCTAfG"
   },
   "source": [
    "**Astuce pratique :** dans colab, vous pouvez exécuter des commandes dans la machine virtuelle sous-jacente (en dehors de python) en les préfixant d'un point d'exclamation, comme ceci :\n",
    "\n",
    "`!ls ./data`\n",
    "\n",
    "Notez que chaque fois que vous appelez une commande avec `!` Colab génère un nouveau shell. Donc les commandes comme `!cd` ne persistent pas entre les lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAAtLJ6INUYT"
   },
   "outputs": [],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFlQkN3STVag"
   },
   "source": [
    "On dirait que les données sont dans le bon dossier ! Pour CIFAR10, l'ensemble d'apprentissage est de 50 000 images et l'ensemble de test est de 10 000 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVuyEK_DNHQd"
   },
   "outputs": [],
   "source": [
    "print(data['train'].__dict__)\n",
    "print(data['test'].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emab4ufITnty"
   },
   "source": [
    "### Inspection des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tpWI3mzNsCW"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(data['train'])\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Afficher les images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Afficher les étiquettes\n",
    "print(\"Labels:\" + ' '.join('%9s' % data['classes'][labels[j]] for j in range(8)))\n",
    "\n",
    "flat = torch.flatten(images, 1)\n",
    "print(images.size())\n",
    "print(flat.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZIOXDp4TskV"
   },
   "source": [
    "## Définir le réseau\n",
    "\n",
    "### SimpleNet\n",
    "Essayons d'abord le réseau simple `SimpleNet` utilisé lors du premier tutoriel. Note : le nombre d'entrées a changé puisque les images en entrée sont maintenant des images RGB de taille 32x32 (32x32x3 = 3072)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWXiqJ8fOTt6"
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, inputs=3072, hidden=512, outputs=10):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputs, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # Convertit une image en vecteur\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy9ndWnSRmpg"
   },
   "source": [
    "### CNN\n",
    "\n",
    "Notre réseau de neurones à convolution est simple pour commencer. Il a 3 couches de convolution (`conv{1-3}`) suivi d'une couche entièrement connectée (`fc1`).\n",
    "\n",
    "|Couche|Entrée|Filtres|Sortie|\n",
    "|-|-|-|-|\n",
    "|**conv1**|`32x32x3`|16 filtres `3x3`, stride=2|`16x16x16`|\n",
    "|**conv2**|`16x16x16`|32 filtres `3x3`, stride=2|`8x8x32`|\n",
    "|**conv3**|`8x8x32`|64 filtres `3x3`, stride=2|`4x4x64`|\n",
    "|**fc1**|`1024`|N.A.|`10`|\n",
    "\n",
    "La couche `fc1` recoît un vecteur de taille 1024 en entrée, et retourne en sortie un vecteur de taille 10, représentant les probabilités non-normalisée de chaque classe.\n",
    "\n",
    "**Note :** après la 3e couche de convolution, on doit convertir la carte de caractéristiques entre formats de tenseurs. Le résultat de cette couche est une image de format (NxCxHxW), mais la couche entièrement connectée reçoit un vecteur de taille (NxM).\n",
    "\n",
    "On peut faire cela en utilisant la méthode `x = torch.flatten(x,1)` sur la carte de caractéristiques.\n",
    "\n",
    "Vous pouvez aussi voir dans la méthode `forward` qu'on utilise une fonction d'activation `relu` après chaque convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1B7bc_89Rjaq"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__() # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        # Entrée : image 32x32x3\n",
    "        # 16 filtres de taille 3x3x3 (ils ont aussi 3 canaux)\n",
    "        # stride 2 (sous-échantillonne d'un facteur 2)\n",
    "        # Sortie : image 16x16x16\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "\n",
    "        # Entrée : image 16x16x16\n",
    "        # 32 filtres de taille 3x3x16 filter size (ils ont aussi 16 canaux)\n",
    "        # stride 2 (sous-échantillonne d'un facteur 2)\n",
    "        # Sortie : image 8x8x32\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "\n",
    "        # Entrée : image 8x8x32\n",
    "        # 64 filtres de taille 3x3x32 filter size (ils ont aussi 32 canaux)\n",
    "        # stride 2 (sous-échantillonne d'un facteur 2)\n",
    "        # Sortie : image 4x4x64\n",
    "        # Output image: 4x4x64 -> 1024 neurons\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "\n",
    "        # Couche entièrement connectée\n",
    "        self.fc1 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1) # Conversion de l'image 4x4x64 -> 1024 neurones\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LullDR7pT_ca"
   },
   "source": [
    "### Code d'entraînement\n",
    "\n",
    "Même boucle d'entraînement que pour le premier tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgrhxQ_NOrAH"
   },
   "outputs": [],
   "source": [
    "def train(net, dataloader, epochs=1, lr=0.01, momentum=0.9, decay=0.0, verbose=1):\n",
    "    net.to(device)\n",
    "    losses = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=decay)\n",
    "    for epoch in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for i, batch in enumerate(dataloader, 0):\n",
    "            # Obtenir les entrées; les données forme une liste de [inputs, labels]\n",
    "            inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            # Initialiser les paramètres des gradients à zéro\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Propagation avant (forward) + Rétropropagation (backward) + Optimisation \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # autograd magic ! Calcule toutes les dérivées partielles\n",
    "            optimizer.step() # Effectue un pas dans la direction du gradient\n",
    "\n",
    "            # Affiche des statistiques\n",
    "            losses.append(loss.item())\n",
    "            sum_loss += loss.item()\n",
    "            if i % 100 == 99:    # Affiche chaque 100 mini-batches\n",
    "                if verbose:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                         (epoch + 1, i + 1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "    return losses\n",
    "\n",
    "def accuracy(net, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def smooth(x, size):\n",
    "    return np.convolve(x, np.ones(size)/size, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bt80jS3zUHXw"
   },
   "source": [
    "## Entraînement des réseaux !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZzpV5IfUXk7"
   },
   "source": [
    "### SimpleNet avec Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jeCMeEGOuQX"
   },
   "outputs": [],
   "source": [
    "net = SimpleNet(inputs=3072)\n",
    "\n",
    "losses = train(net, data['train'], epochs=5, lr=.01)\n",
    "plt.plot(smooth(losses,50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(net, data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqOKSMzGUaQi"
   },
   "source": [
    "### ConvNet avec CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdS62eiRQPRx"
   },
   "outputs": [],
   "source": [
    "conv_net = ConvNet()\n",
    "\n",
    "conv_losses = train(conv_net, data['train'], epochs=15, lr=.01)\n",
    "plt.plot(smooth(conv_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(conv_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(conv_net, data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFAQJCnoET54"
   },
   "outputs": [],
   "source": [
    "plt.plot(smooth(losses,50), 'r-')\n",
    "plt.plot(smooth(conv_losses, 50), 'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OILkg6E0SDvI"
   },
   "source": [
    "### Recuit simulé (*Simulated Annealing*)\n",
    "https://en.wikipedia.org/wiki/Simulated_annealing\n",
    "\n",
    "Il peut être utile de réduire lenteement le taux d'apprentissage avec le temps pour aider le réseau à converger vers un meilleur optimum local. Essayons cette technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4rlUxOiPrkl"
   },
   "outputs": [],
   "source": [
    "anneal_net = ConvNet()\n",
    "\n",
    "anneal_losses =  train(anneal_net, data['train'], epochs=5, lr=.1)\n",
    "anneal_losses += train(anneal_net, data['train'], epochs=5, lr=.01)\n",
    "anneal_losses += train(anneal_net, data['train'], epochs=5, lr=.001)\n",
    "\n",
    "plt.plot(smooth(anneal_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(anneal_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(anneal_net, data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNA4U0OCSsGX"
   },
   "source": [
    "### Normalisation par lot (*Batch Normalization*)\n",
    "L'entraînement est meilleur et plus rapide avec `batchnorm`. Ajoutons cette couche à notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM9LFxWnS5_H"
   },
   "outputs": [],
   "source": [
    "class ConvBNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBNNet, self).__init__() # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.fc1 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZXuotZaOiNV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "norm_net = ConvBNNet()\n",
    "\n",
    "norm_losses = train(norm_net, data['train'], epochs=15, lr=.01)\n",
    "\n",
    "plt.plot(smooth(norm_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(norm_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(norm_net, data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8YEJTuwQLA1"
   },
   "outputs": [],
   "source": [
    "plt.plot(smooth(losses,50), 'r-', label='SimpleNet')\n",
    "plt.plot(smooth(conv_losses, 50), 'b-', label='ConvNet')\n",
    "plt.plot(smooth(norm_losses, 50), 'g-', label='ConvNet+BatchNorm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UE8S3E3P0X9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Augmentation du taux d'apprentissage\n",
    "\n",
    "lr_net = ConvBNNet()\n",
    "\n",
    "lr_losses = train(lr_net, data['train'], epochs=15, lr=.1)\n",
    "\n",
    "plt.plot(smooth(lr_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(lr_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(lr_net, data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RefGZ70sRw3r"
   },
   "outputs": [],
   "source": [
    "plt.plot(smooth(norm_losses, 50), 'g-', label='lr=0.01')\n",
    "plt.plot(smooth(lr_losses, 50), 'r-', label='lr=0.1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30q05yadSe-9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ConvNet + BatchNorm + simulated annealing\n",
    "\n",
    "anneal2_net = ConvBNNet()\n",
    "\n",
    "anneal2_losses =  train(anneal2_net, data['train'], epochs=5, lr=.1)\n",
    "anneal2_losses += train(anneal2_net, data['train'], epochs=5, lr=.01)\n",
    "anneal2_losses += train(anneal2_net, data['train'], epochs=5, lr=.001)\n",
    "\n",
    "\n",
    "plt.plot(smooth(anneal2_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(anneal2_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(anneal2_net, data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiwfHa_ZFui4"
   },
   "source": [
    "### Décroissance des poids (*Weight Decay*)\n",
    "\n",
    "On peut essayer d'ajouter une décroissance des poids, car le modèle actuel surajuste les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8qzqE4TF0KV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decay_net = ConvBNNet()\n",
    "\n",
    "decay_losses =  train(decay_net, data['train'], epochs=5, lr=.1  , decay = .0005)\n",
    "decay_losses += train(decay_net, data['train'], epochs=5, lr=.01 , decay = .0005)\n",
    "decay_losses += train(decay_net, data['train'], epochs=5, lr=.001, decay = .0005)\n",
    "\n",
    "\n",
    "plt.plot(smooth(decay_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(decay_net, data['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(decay_net, data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GV6dB2hGVFwF"
   },
   "outputs": [],
   "source": [
    "#plt.plot(smooth(losses,50), 'r-')\n",
    "#plt.plot(smooth(conv_losses, 50), 'r-')\n",
    "#plt.plot(smooth(norm_losses, 50), 'g-')\n",
    "plt.plot(smooth(anneal2_losses, 50), 'b-')\n",
    "plt.plot(smooth(decay_losses, 50), 'm-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdfRaxZxWtfZ"
   },
   "source": [
    "#### Augmentation des données (*Data Augmentation*)\n",
    "\n",
    "La précision pour l'entraînement est beaucoup plus élevée que la précision pour les données de test, ce qui indique un surajustement. Ajoutoins l'augmentation des données pour l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-5etXowXEyV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_aug = get_cifar10_data(augmentation=True)\n",
    "data_net = ConvBNNet()\n",
    "\n",
    "data_losses =  train(data_net, data_aug['train'], epochs=5, lr=.1  , decay=.0005)\n",
    "data_losses += train(data_net, data_aug['train'], epochs=5, lr=.01 , decay=.0005)\n",
    "data_losses += train(data_net, data_aug['train'], epochs=5, lr=.001, decay=.0005)\n",
    "\n",
    "\n",
    "plt.plot(smooth(data_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(data_net, data_aug['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(data_net, data_aug['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeHcb2GUZS_W"
   },
   "outputs": [],
   "source": [
    "plt.plot(smooth(decay_losses, 50), 'r-')\n",
    "plt.plot(smooth(data_losses, 50), 'g-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFepNt-MZz4h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_net = ConvBNNet()\n",
    "\n",
    "final_losses =  train(final_net, data_aug['train'], epochs=15, lr=.1  , decay=.0005)\n",
    "final_losses += train(final_net, data_aug['train'], epochs=5, lr=.01 , decay=.0005)\n",
    "final_losses += train(final_net, data_aug['train'], epochs=5, lr=.001, decay=.0005)\n",
    "\n",
    "\n",
    "plt.plot(smooth(final_losses, 50))\n",
    "\n",
    "print(\"Précision d'entraînement : %f\" % accuracy(final_net, data_aug['train']))\n",
    "print(\"Précision de test : %f\" % accuracy(final_net, data_aug['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ1-ePKDcQod"
   },
   "outputs": [],
   "source": [
    "plt.plot(smooth(decay_losses, 50), 'r-')\n",
    "plt.plot(smooth(data_losses, 50), 'g-')\n",
    "plt.plot(smooth(final_losses, 50), 'b-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester le réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "dataiter = iter(data['test'])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "idx = random.randint(0, len(images-4))\n",
    "images = images[idx:idx+4]\n",
    "labels = labels[idx:idx+4]\n",
    "\n",
    "# Afficher les images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Vérité de terrain (GroundTruth): ', ' '.join('%5s' % data['classes'][labels[j]] for j in range(4)))\n",
    "outputs = final_net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Prédiction : ', ' '.join('%5s' % data['classes'][predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Tutorial 2 - CNNs in PyTorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
